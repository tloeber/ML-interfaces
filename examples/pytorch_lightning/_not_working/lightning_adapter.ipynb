{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note on license:\n",
    "This notebook uses examples from the official Lightning repo, which is licensed under Apache 2.0. In compliance with the Apache license, any reused code is relicensed under the license in this project (as of September 2023, the MIT license), but I list modifications to the original code here:\n",
    "- Refactor PyTorch Lightning example code so it can be used with an adapter class from this project.\n",
    "\n",
    "# Why this example is abandoned\n",
    "This turned out to not be a good example code, because the Lightning CLI conflicts with the Jupyter notebook API. I verified that the original pure-Python version of the code also does not run within a Jupyter notebook. While I did find several suggestions on StackOverflow for how to try to remediate this, I did not find a quick way to apply this here, so I decided to instead take a different example.\n",
    "\n",
    "# Why this notebook is not deleted yet\n",
    "The way to create an adapter class should be similar for other examples, but I have not had time to port this over yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't use strict note for type checking yet\n",
    "%nb_mypy mypy-options --pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>27: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>27: \u001b[34mnote:\u001b[m Use \u001b[m\u001b[1m\"-> None\"\u001b[m if function does not return a value\u001b[m\n",
      "<cell>31: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>31: \u001b[34mnote:\u001b[m Use \u001b[m\u001b[1m\"-> None\"\u001b[m if function does not return a value\u001b[m\n",
      "<cell>39: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>48: \u001b[1m\u001b[31merror:\u001b[m Missing type parameters for generic type \u001b[m\u001b[1m\"ndarray\"\u001b[m  \u001b[m\u001b[33m[type-arg]\u001b[m\n",
      "<cell>48: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>52: \u001b[1m\u001b[31merror:\u001b[m Missing type parameters for generic type \u001b[m\u001b[1m\"ndarray\"\u001b[m  \u001b[m\u001b[33m[type-arg]\u001b[m\n",
      "<cell>64: \u001b[34mnote:\u001b[m \u001b[m\u001b[1m\"StructuredDataSetImplementation\"\u001b[m defined here\u001b[m\n",
      "<cell>69: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>73: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>77: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>78: \u001b[1m\u001b[31merror:\u001b[m Unexpected keyword argument \u001b[m\u001b[1m\"pd_data_frame\"\u001b[m for \u001b[m\u001b[1m\"StructuredDataSetImplementation\"\u001b[m  \u001b[m\u001b[33m[call-arg]\u001b[m\n",
      "<cell>78: \u001b[1m\u001b[31merror:\u001b[m Unexpected keyword argument \u001b[m\u001b[1m\"target_name\"\u001b[m for \u001b[m\u001b[1m\"StructuredDataSetImplementation\"\u001b[m  \u001b[m\u001b[33m[call-arg]\u001b[m\n",
      "<cell>81: \u001b[1m\u001b[31merror:\u001b[m Returning Any from function declared to return \u001b[m\u001b[1m\"DataFrame\"\u001b[m  \u001b[m\u001b[33m[no-any-return]\u001b[m\n",
      "<cell>81: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"StructuredDataSetImplementation\"\u001b[m has no attribute \u001b[m\u001b[1m\"data\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>84: \u001b[1m\u001b[31merror:\u001b[m Missing type parameters for generic type \u001b[m\u001b[1m\"ndarray\"\u001b[m  \u001b[m\u001b[33m[type-arg]\u001b[m\n",
      "<cell>84: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>86: \u001b[1m\u001b[31merror:\u001b[m Unexpected keyword argument \u001b[m\u001b[1m\"pd_data_frame\"\u001b[m for \u001b[m\u001b[1m\"StructuredDataSetImplementation\"\u001b[m  \u001b[m\u001b[33m[call-arg]\u001b[m\n",
      "<cell>88: \u001b[1m\u001b[31merror:\u001b[m Missing type parameters for generic type \u001b[m\u001b[1m\"ndarray\"\u001b[m  \u001b[m\u001b[33m[type-arg]\u001b[m\n",
      "<cell>89: \u001b[1m\u001b[31merror:\u001b[m Returning Any from function declared to return \u001b[m\u001b[1m\"ndarray[Any, Any]\"\u001b[m  \u001b[m\u001b[33m[no-any-return]\u001b[m\n",
      "<cell>89: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"StructuredDataSetImplementation\"\u001b[m has no attribute \u001b[m\u001b[1m\"data\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>92: \u001b[1m\u001b[31merror:\u001b[m Returning Any from function declared to return \u001b[m\u001b[1m\"list[str]\"\u001b[m  \u001b[m\u001b[33m[no-any-return]\u001b[m\n",
      "<cell>92: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"StructuredDataSetImplementation\"\u001b[m has no attribute \u001b[m\u001b[1m\"columns\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n"
     ]
    }
   ],
   "source": [
    "from abc import abstractmethod, abstractproperty, ABC\n",
    "from typing import Any, TypeAlias, NewType, TypeVar, Type, NoReturn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Interface\n",
    "# =========\n",
    "\n",
    "class DataSetInterface(ABC):\n",
    "    \"\"\"\n",
    "    This serves as the *abstract* type under which all the concrete dataset \n",
    "    interfaces fall. We can use when we want to depend only on the data set \n",
    "    abstraction, but not the concrete type of data set. \n",
    "    \n",
    "    At the moment, this interface does not yet defined any shared behavior,\n",
    "    so it would also be possible to use virtual subclasses (e.g., registering) \n",
    "    instead. However, we want to keep the option open for the future to define \n",
    "    shared behavior that all the concrete dataset interfaces must implement.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "class StructuredDataSetInterface(DataSetInterface):\n",
    "    \n",
    "    @abstractproperty\n",
    "    def X(self):\n",
    "        pass\n",
    "\n",
    "    @abstractproperty\n",
    "    def y(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Format conversions\n",
    "    # ------------------\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def from_pandas(cls, input_data: pd.DataFrame):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def to_pandas(self) -> pd.DataFrame:\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def from_numpy(cls, input_data: np.ndarray):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def to_numpy(self) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_column_names(self) -> list[str]:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Implementation\n",
    "# ==============\n",
    "\n",
    "class StructuredDataSetImplementation(DataSetInterface):\n",
    "    def __init__(self, X: pd.DataFrame, y: pd.DataFrame):\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "\n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._X\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._y\n",
    "    \n",
    "    @classmethod\n",
    "    def from_pandas(cls, input_data: pd.DataFrame, target_name: str):\n",
    "        return cls(pd_data_frame=input_data, target_name=target_name)\n",
    "\n",
    "    def to_pandas(self) -> pd.DataFrame:\n",
    "        return self.data    \n",
    "            \n",
    "    @classmethod\n",
    "    def from_numpy(cls, input_data: np.ndarray):\n",
    "        pd_data_frame=pd.DataFrame(input_data)\n",
    "        return cls(pd_data_frame=pd_data_frame)\n",
    "\n",
    "    def to_numpy(self) -> np.ndarray:\n",
    "        return self.data.to_numpy()\n",
    "    \n",
    "    def get_column_names(self) -> list[str]:\n",
    "        return self.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>25: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>29: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>33: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# Container\n",
    "# =========\n",
    "\n",
    "class DataContainerInterface(ABC):\n",
    "    @abstractproperty\n",
    "    def train(self) -> DataSetInterface:\n",
    "        pass\n",
    "\n",
    "    @abstractproperty\n",
    "    def val(self) -> DataSetInterface:\n",
    "        pass\n",
    "\n",
    "    @abstractproperty\n",
    "    def test(self) -> DataSetInterface:\n",
    "        pass\n",
    "\n",
    "\n",
    "class DataContainer():\n",
    "    def __init__(self, train: DataSetInterface, val: DataSetInterface, test: DataSetInterface):\n",
    "        self._train = train\n",
    "        self._val = val\n",
    "        self._test = test\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self._train\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self._test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>4: \u001b[1m\u001b[31merror:\u001b[m Missing type parameters for generic type \u001b[m\u001b[1m\"Dataset\"\u001b[m  \u001b[m\u001b[33m[type-arg]\u001b[m\n",
      "<cell>8: \u001b[1m\u001b[31merror:\u001b[m Function is missing a type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>11: \u001b[1m\u001b[31merror:\u001b[m Missing type parameters for generic type \u001b[m\u001b[1m\"Dataset\"\u001b[m  \u001b[m\u001b[33m[type-arg]\u001b[m\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset as TorchDataset\n",
    "\n",
    "class ImageDataSetImplementation(DataSetInterface):\n",
    "    def __init__(self, data: TorchDataset):\n",
    "        self.data = data\n",
    "    \n",
    "    @classmethod\n",
    "    def from_torch(cls, data):\n",
    "        return cls(data=data)\n",
    "\n",
    "    def to_torch(self) -> TorchDataset:\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>17: \u001b[1m\u001b[31merror:\u001b[m Call to untyped function \u001b[m\u001b[1m\"from_torch\"\u001b[m of \u001b[m\u001b[1m\"ImageDataSetImplementation\"\u001b[m in typed context  \u001b[m\u001b[33m[no-untyped-call]\u001b[m\n",
      "<cell>18: \u001b[1m\u001b[31merror:\u001b[m Call to untyped function \u001b[m\u001b[1m\"from_torch\"\u001b[m of \u001b[m\u001b[1m\"ImageDataSetImplementation\"\u001b[m in typed context  \u001b[m\u001b[33m[no-untyped-call]\u001b[m\n",
      "<cell>19: \u001b[1m\u001b[31merror:\u001b[m Call to untyped function \u001b[m\u001b[1m\"from_torch\"\u001b[m of \u001b[m\u001b[1m\"ImageDataSetImplementation\"\u001b[m in typed context  \u001b[m\u001b[33m[no-untyped-call]\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# Create example data\n",
    "# ===================\n",
    " \n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "DATA_DIR = './data'\n",
    "\n",
    "mnist_train_and_val = MNIST(root=DATA_DIR, train=True, download=True)\n",
    "mnist_train, mnist_val = random_split(\n",
    "    dataset=mnist_train_and_val, \n",
    "    lengths=[.9, .1]\n",
    ")\n",
    "mnist_test = MNIST(root=DATA_DIR, train=False, download=True)\n",
    "\n",
    "mnist_train = ImageDataSetImplementation.from_torch(mnist_train)\n",
    "mnist_val = ImageDataSetImplementation.from_torch(mnist_val)\n",
    "mnist_test = ImageDataSetImplementation.from_torch(mnist_test)\n",
    "\n",
    "mnist_container = DataContainer(\n",
    "    train=mnist_train,\n",
    "    val=mnist_val,\n",
    "    test=mnist_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from lightning.pytorch import cli_lightning_logo, LightningDataModule, LightningModule\n",
    "from lightning.pytorch.cli import LightningCLI\n",
    "from lightning.pytorch.demos.mnist_datamodule import MNIST\n",
    "from lightning.pytorch.utilities.imports import _TORCHVISION_AVAILABLE\n",
    "\n",
    "if _TORCHVISION_AVAILABLE:\n",
    "    from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>1: \u001b[1m\u001b[31merror:\u001b[m Function is missing a type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>3: \u001b[1m\u001b[31merror:\u001b[m Function is missing a type annotation for one or more arguments  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>7: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>13: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>16: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"TorchDataloader\"\u001b[m has no attribute \u001b[m\u001b[1m\"batch_size\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>19: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>22: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"TorchDataloader\"\u001b[m has no attribute \u001b[m\u001b[1m\"batch_size\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>25: \u001b[1m\u001b[31merror:\u001b[m Function is missing a type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n"
     ]
    }
   ],
   "source": [
    "def create_torch_dataloader(data_container, batch_size):  # -> type[TorchDataloader]:\n",
    "    class TorchDataloader(LightningDataModule):\n",
    "        def __init__(self, data_container) -> None:\n",
    "            super().__init__()\n",
    "            self.data_container = data_container\n",
    "\n",
    "        def train_dataloader(self):\n",
    "            return DataLoader(\n",
    "                self.data_container.train.to_torch(),\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "\n",
    "        def val_dataloader(self):\n",
    "            return DataLoader(\n",
    "                self.data_container.val.to_torch(), \n",
    "                batch_size=self.batch_size\n",
    "            )\n",
    "\n",
    "        def test_dataloader(self):\n",
    "            return DataLoader(\n",
    "                self.data_container.test.to_torch(), \n",
    "                batch_size=self.batch_size\n",
    "            )\n",
    "\n",
    "        def predict_dataloader(self, data):\n",
    "            pass\n",
    "\n",
    "    return TorchDataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>36: \u001b[1m\u001b[31merror:\u001b[m Function is missing a return type annotation  \u001b[m\u001b[33m[no-untyped-def]\u001b[m\n",
      "<cell>36: \u001b[34mnote:\u001b[m Use \u001b[m\u001b[1m\"-> None\"\u001b[m if function does not return a value\u001b[m\n",
      "<cell>40: \u001b[1m\u001b[31merror:\u001b[m Call to untyped function \u001b[m\u001b[1m\"create_torch_dataloader\"\u001b[m in typed context  \u001b[m\u001b[33m[no-untyped-call]\u001b[m\n",
      "<cell>63: \u001b[1m\u001b[31merror:\u001b[m Argument \u001b[m\u001b[1m\"classifier\"\u001b[m to \u001b[m\u001b[1m\"PytorchLightningAdapter\"\u001b[m has incompatible type \u001b[m\u001b[1m\"type[LitClassifier]\"\u001b[m; expected \u001b[m\u001b[1m\"LightningModule\"\u001b[m  \u001b[m\u001b[33m[arg-type]\u001b[m\n",
      "<cell>67: \u001b[1m\u001b[31merror:\u001b[m Call to untyped function \u001b[m\u001b[1m\"cli_main\"\u001b[m in typed context  \u001b[m\u001b[33m[no-untyped-call]\u001b[m\n",
      "usage: ipykernel_launcher.py [-h] [-c CONFIG] [--print_config[=flags]]\n",
      "                             [--seed_everything SEED_EVERYTHING]\n",
      "                             [--trainer CONFIG]\n",
      "                             [--trainer.accelerator.help CLASS_PATH_OR_NAME]\n",
      "                             [--trainer.accelerator ACCELERATOR]\n",
      "                             [--trainer.strategy.help CLASS_PATH_OR_NAME]\n",
      "                             [--trainer.strategy STRATEGY]\n",
      "                             [--trainer.devices DEVICES]\n",
      "                             [--trainer.num_nodes NUM_NODES]\n",
      "                             [--trainer.precision PRECISION]\n",
      "                             [--trainer.logger.help CLASS_PATH_OR_NAME]\n",
      "                             [--trainer.logger LOGGER]\n",
      "                             [--trainer.callbacks.help CLASS_PATH_OR_NAME]\n",
      "                             [--trainer.callbacks CALLBACKS]\n",
      "                             [--trainer.fast_dev_run FAST_DEV_RUN]\n",
      "                             [--trainer.max_epochs MAX_EPOCHS]\n",
      "                             [--trainer.min_epochs MIN_EPOCHS]\n",
      "                             [--trainer.max_steps MAX_STEPS]\n",
      "                             [--trainer.min_steps MIN_STEPS]\n",
      "                             [--trainer.max_time MAX_TIME]\n",
      "                             [--trainer.limit_train_batches LIMIT_TRAIN_BATCHES]\n",
      "                             [--trainer.limit_val_batches LIMIT_VAL_BATCHES]\n",
      "                             [--trainer.limit_test_batches LIMIT_TEST_BATCHES]\n",
      "                             [--trainer.limit_predict_batches LIMIT_PREDICT_BATCHES]\n",
      "                             [--trainer.overfit_batches OVERFIT_BATCHES]\n",
      "                             [--trainer.val_check_interval VAL_CHECK_INTERVAL]\n",
      "                             [--trainer.check_val_every_n_epoch CHECK_VAL_EVERY_N_EPOCH]\n",
      "                             [--trainer.num_sanity_val_steps NUM_SANITY_VAL_STEPS]\n",
      "                             [--trainer.log_every_n_steps LOG_EVERY_N_STEPS]\n",
      "                             [--trainer.enable_checkpointing {true,false,null}]\n",
      "                             [--trainer.enable_progress_bar {true,false,null}]\n",
      "                             [--trainer.enable_model_summary {true,false,null}]\n",
      "                             [--trainer.accumulate_grad_batches ACCUMULATE_GRAD_BATCHES]\n",
      "                             [--trainer.gradient_clip_val GRADIENT_CLIP_VAL]\n",
      "                             [--trainer.gradient_clip_algorithm GRADIENT_CLIP_ALGORITHM]\n",
      "                             [--trainer.deterministic DETERMINISTIC]\n",
      "                             [--trainer.benchmark {true,false,null}]\n",
      "                             [--trainer.inference_mode {true,false}]\n",
      "                             [--trainer.use_distributed_sampler {true,false}]\n",
      "                             [--trainer.profiler.help CLASS_PATH_OR_NAME]\n",
      "                             [--trainer.profiler PROFILER]\n",
      "                             [--trainer.detect_anomaly {true,false}]\n",
      "                             [--trainer.barebones {true,false}]\n",
      "                             [--trainer.plugins.help CLASS_PATH_OR_NAME]\n",
      "                             [--trainer.plugins PLUGINS]\n",
      "                             [--trainer.sync_batchnorm {true,false}]\n",
      "                             [--trainer.reload_dataloaders_every_n_epochs RELOAD_DATALOADERS_EVERY_N_EPOCHS]\n",
      "                             [--trainer.default_root_dir DEFAULT_ROOT_DIR]\n",
      "                             [--model CONFIG]\n",
      "                             [--model.backbone.help CLASS_PATH_OR_NAME]\n",
      "                             [--model.backbone BACKBONE]\n",
      "                             [--model.learning_rate LEARNING_RATE]\n",
      "                             [--data CONFIG]\n",
      "                             [--data.data_container DATA_CONTAINER]\n",
      "                             [--optimizer.help CLASS_PATH_OR_NAME]\n",
      "                             [--optimizer CONFIG | CLASS_PATH_OR_NAME | .INIT_ARG_NAME VALUE]\n",
      "                             [--lr_scheduler.help CLASS_PATH_OR_NAME]\n",
      "                             [--lr_scheduler CONFIG | CLASS_PATH_OR_NAME | .INIT_ARG_NAME VALUE]\n",
      "ipykernel_launcher.py: error: Unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"2f5adfc0-13d2-4bf9-a7c5-46c031f15b57\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/home/thomas/.local/share/jupyter/runtime/kernel-v2-3229l25oqDXV71Y.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/.cache/pypoetry/virtualenvs/oject-oriented-ml-2RS15okd-py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from lightning_adapter_extras import LitClassifier\n",
    "\n",
    "# Inner config objects\n",
    "class SaveConfigKwargs(BaseModel): \n",
    "    overwrite: bool\n",
    "    \n",
    "\n",
    "# Main config\n",
    "class Config(BaseModel):\n",
    "    batch_size: int\n",
    "    # learning_rate: float = 0.001\n",
    "    # hidden_dim: int = 128\n",
    "    # data_dir: str = \"./data\"\n",
    "    run: bool\n",
    "    save_config_kwargs: SaveConfigKwargs\n",
    "    seed_everything_default: int = 1\n",
    "        \n",
    "\n",
    "class PytorchLightningAdapter():\n",
    "    def __init__(\n",
    "        self, \n",
    "        classifier: LightningModule,\n",
    "        data_container: DataContainer,\n",
    "        config: Config,\n",
    "    ) -> None:\n",
    "        self.data_container = data_container\n",
    "        self.classifier = classifier\n",
    "        self.config = config\n",
    "\n",
    "    # def optimize_hyperparameters(self):\n",
    "    # def fit(self) -> None:\n",
    "    # def predict(self) -> DataSetInterface:\n",
    "\n",
    "\n",
    "    def cli_main(self):\n",
    "        \n",
    "        cli = LightningCLI(\n",
    "            model_class=self.classifier,\n",
    "            datamodule_class= create_torch_dataloader(\n",
    "                self.data_container, \n",
    "                batch_size=config.batch_size\n",
    "            ),\n",
    "            seed_everything_default=self.config.seed_everything_default,\n",
    "            save_config_kwargs=self.config.save_config_kwargs.dict(),\n",
    "            run=self.config.run,\n",
    "        )\n",
    "        cli.trainer.fit(cli.model, datamodule=cli.datamodule)\n",
    "        cli.trainer.test(ckpt_path=\"best\", datamodule=cli.datamodule)\n",
    "        predictions = cli.trainer.predict(ckpt_path=\"best\", datamodule=cli.datamodule)\n",
    "        if predictions is not None:\n",
    "            print(predictions[0])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = Config(\n",
    "        batch_size=64,\n",
    "        save_config_kwargs=SaveConfigKwargs(overwrite=True),\n",
    "        run=False,\n",
    "    )\n",
    "    \n",
    "    ptl = PytorchLightningAdapter(\n",
    "        classifier=LitClassifier,\n",
    "        data_container=mnist_container,\n",
    "        config=config,\n",
    "    )\n",
    "    ptl.cli_main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oject-oriented-ml-2RS15okd-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
